{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35bcf11a",
   "metadata": {},
   "source": [
    "# Heart Disease Prediction Model\n",
    "\n",
    "This notebook demonstrates training a machine learning model to predict heart disease.\n",
    "\n",
    "**Features:** age, sex, chest pain type, blood pressure, cholesterol, fasting blood sugar, ECG results, max heart rate, exercise angina, ST depression, slope, ca, thal  \n",
    "**Target:** Heart disease presence (0 = no, 1 = yes)  \n",
    "**Model:** Classification (SVM, Random Forest, Logistic Regression, etc.)\n",
    "\n",
    "**Note:** This is a template notebook. You'll need to provide the heart disease dataset to run this completely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688f6952",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44f04aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix, \n",
    "    roc_auc_score, roc_curve, precision_score, recall_score, f1_score\n",
    ")\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plot styles\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"‚úì Libraries imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5c1ff3",
   "metadata": {},
   "source": [
    "## 2. Load Dataset\n",
    "\n",
    "**Dataset Source:** Heart disease dataset (UCI ML Repository / Kaggle)  \n",
    "**Columns:** age, sex, cp, trestbps, chol, fbs, restecg, thalach, exang, oldpeak, slope, ca, thal, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545cc3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Replace with actual dataset path\n",
    "# Common dataset: https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset\n",
    "\n",
    "# Example loading (uncomment and modify path):\n",
    "# df = pd.read_csv('path/to/heart_disease.csv')\n",
    "\n",
    "# For demonstration, create synthetic data structure\n",
    "print(\"Expected columns:\")\n",
    "columns = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', \n",
    "           'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']\n",
    "print(columns)\n",
    "\n",
    "# Load your dataset here:\n",
    "# df = pd.read_csv('your_heart_disease_data.csv')\n",
    "# display(df.head())\n",
    "# print(f\"Dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28e890b",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99927116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment when you have data loaded:\n",
    "# print(\"Dataset Info:\")\n",
    "# print(df.info())\n",
    "# print(\"\\nStatistical Summary:\")\n",
    "# display(df.describe())\n",
    "# print(\"\\nMissing values:\")\n",
    "# print(df.isnull().sum())\n",
    "# print(\"\\nTarget distribution:\")\n",
    "# print(df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97154e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations\n",
    "# Uncomment when data is loaded:\n",
    "# fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "# \n",
    "# # Target distribution\n",
    "# df['target'].value_counts().plot(kind='bar', ax=axes[0,0], color=['green', 'red'])\n",
    "# axes[0,0].set_title('Heart Disease Distribution')\n",
    "# axes[0,0].set_xlabel('0=No Disease, 1=Disease')\n",
    "# \n",
    "# # Age distribution\n",
    "# df['age'].hist(bins=20, ax=axes[0,1], color='skyblue')\n",
    "# axes[0,1].set_title('Age Distribution')\n",
    "# \n",
    "# # Correlation heatmap\n",
    "# sns.heatmap(df.corr(), annot=False, cmap='coolwarm', ax=axes[1,0])\n",
    "# axes[1,0].set_title('Feature Correlation')\n",
    "# \n",
    "# # Box plot for age by target\n",
    "# df.boxplot(column='age', by='target', ax=axes[1,1])\n",
    "# axes[1,1].set_title('Age by Heart Disease Status')\n",
    "# \n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed20b1a",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92c1957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and adapt when data is loaded:\n",
    "# # Separate features and target\n",
    "# X = df.drop('target', axis=1)\n",
    "# y = df['target']\n",
    "# \n",
    "# # Handle missing values if any\n",
    "# X = X.fillna(X.median())\n",
    "# \n",
    "# print(f\"Features shape: {X.shape}\")\n",
    "# print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666a13ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=42, stratify=y\n",
    "# )\n",
    "# \n",
    "# print(f\"Training set: {X_train.shape}\")\n",
    "# print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc95e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "# \n",
    "# print(\"‚úì Features scaled!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9351fed2",
   "metadata": {},
   "source": [
    "## 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3fd172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multiple models and compare\n",
    "# models = {\n",
    "#     'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "#     'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "#     'SVM': SVC(probability=True, kernel='rbf'),\n",
    "#     'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "# }\n",
    "# \n",
    "# results = {}\n",
    "# for name, model in models.items():\n",
    "#     model.fit(X_train_scaled, y_train)\n",
    "#     y_pred = model.predict(X_test_scaled)\n",
    "#     acc = accuracy_score(y_test, y_pred)\n",
    "#     results[name] = acc\n",
    "#     print(f\"{name:25s} Accuracy: {acc:.4f}\")\n",
    "# \n",
    "# # Select best model\n",
    "# best_model_name = max(results, key=results.get)\n",
    "# best_model = models[best_model_name]\n",
    "# print(f\"\\nüèÜ Best Model: {best_model_name} ({results[best_model_name]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e12614",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54355491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed evaluation of best model\n",
    "# y_pred = best_model.predict(X_test_scaled)\n",
    "# y_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "# \n",
    "# print(\"Classification Report:\")\n",
    "# print(\"=\"*60)\n",
    "# print(classification_report(y_test, y_pred, target_names=['No Disease', 'Disease']))\n",
    "# \n",
    "# print(f\"\\nROC-AUC Score: {roc_auc_score(y_test, y_proba):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef6d1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "#             xticklabels=['No Disease', 'Disease'],\n",
    "#             yticklabels=['No Disease', 'Disease'])\n",
    "# plt.title('Confusion Matrix - Heart Disease Prediction')\n",
    "# plt.ylabel('Actual')\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f913691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Confusion Matrix Visualization\n",
    "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "# \n",
    "# # Standard confusion matrix\n",
    "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "#             xticklabels=['No Disease', 'Disease'],\n",
    "#             yticklabels=['No Disease', 'Disease'],\n",
    "#             ax=ax1, cbar_kws={'label': 'Count'})\n",
    "# ax1.set_title('Confusion Matrix (Counts)', fontsize=14, fontweight='bold')\n",
    "# ax1.set_ylabel('Actual', fontsize=12)\n",
    "# ax1.set_xlabel('Predicted', fontsize=12)\n",
    "# \n",
    "# # Normalized confusion matrix\n",
    "# cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "# sns.heatmap(cm_norm, annot=True, fmt='.2%', cmap='Blues',\n",
    "#             xticklabels=['No Disease', 'Disease'],\n",
    "#             yticklabels=['No Disease', 'Disease'],\n",
    "#             ax=ax2, cbar_kws={'label': 'Percentage'})\n",
    "# ax2.set_title('Normalized Confusion Matrix (%)', fontsize=14, fontweight='bold')\n",
    "# ax2.set_ylabel('Actual', fontsize=12)\n",
    "# ax2.set_xlabel('Predicted', fontsize=12)\n",
    "# \n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "# \n",
    "# # Print detailed metrics from confusion matrix\n",
    "# tn, fp, fn, tp = cm.ravel()\n",
    "# print(f\"\\nDetailed Breakdown:\")\n",
    "# print(f\"  True Negatives:  {tn} - Correctly identified healthy patients\")\n",
    "# print(f\"  False Positives: {fp} - Healthy patients incorrectly flagged\")\n",
    "# print(f\"  False Negatives: {fn} - Heart disease cases missed ‚ö†Ô∏è\")\n",
    "# print(f\"  True Positives:  {tp} - Correctly identified heart disease\")\n",
    "# print(f\"\\nSensitivity/Recall: {tp/(tp+fn):.2%} - Detection rate\")\n",
    "# print(f\"Specificity:        {tn/(tn+fp):.2%} - True negative rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3964105",
   "metadata": {},
   "source": [
    "### Enhanced Confusion Matrix with Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147907d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc_score(y_test, y_proba):.3f})')\n",
    "# plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('ROC Curve - Heart Disease Prediction')\n",
    "# plt.legend()\n",
    "# plt.grid(alpha=0.3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9cc842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance (for tree-based models)\n",
    "# if hasattr(best_model, 'feature_importances_'):\n",
    "#     importance_df = pd.DataFrame({\n",
    "#         'feature': X.columns,\n",
    "#         'importance': best_model.feature_importances_\n",
    "#     }).sort_values('importance', ascending=False)\n",
    "#     \n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.barh(importance_df['feature'], importance_df['importance'], color='coral')\n",
    "#     plt.xlabel('Importance Score', fontsize=12)\n",
    "#     plt.title('Feature Importance - Heart Disease Prediction', fontsize=14, fontweight='bold')\n",
    "#     plt.gca().invert_yaxis()\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "#     \n",
    "#     print(\"\\nTop 5 Most Important Features:\")\n",
    "#     print(importance_df.head().to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc57f97",
   "metadata": {},
   "source": [
    "### Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bce9cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive metrics visualization\n",
    "# metrics = {\n",
    "#     'Accuracy': accuracy_score(y_test, y_pred),\n",
    "#     'Precision': precision_score(y_test, y_pred),\n",
    "#     'Recall': recall_score(y_test, y_pred),\n",
    "#     'F1-Score': f1_score(y_test, y_pred),\n",
    "#     'ROC-AUC': roc_auc_score(y_test, y_proba)\n",
    "# }\n",
    "# \n",
    "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "# \n",
    "# # Metrics bar plot\n",
    "# colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12', '#9b59b6']\n",
    "# bars = ax1.bar(metrics.keys(), metrics.values(), color=colors)\n",
    "# ax1.set_ylim([0, 1])\n",
    "# ax1.set_ylabel('Score', fontsize=12)\n",
    "# ax1.set_title('Performance Metrics', fontsize=14, fontweight='bold')\n",
    "# ax1.axhline(y=0.8, color='gray', linestyle='--', alpha=0.5, label='80% threshold')\n",
    "# ax1.grid(axis='y', alpha=0.3)\n",
    "# ax1.legend()\n",
    "# \n",
    "# for i, (key, value) in enumerate(metrics.items()):\n",
    "#     ax1.text(i, value + 0.02, f'{value:.3f}', ha='center', fontweight='bold')\n",
    "# \n",
    "# ax1.set_xticklabels(metrics.keys(), rotation=15, ha='right')\n",
    "# \n",
    "# # Model comparison\n",
    "# ax2.bar(results.keys(), results.values(), color='steelblue')\n",
    "# ax2.set_ylim([0, 1])\n",
    "# ax2.set_ylabel('Accuracy', fontsize=12)\n",
    "# ax2.set_title('Model Comparison', fontsize=14, fontweight='bold')\n",
    "# ax2.grid(axis='y', alpha=0.3)\n",
    "# ax2.set_xticklabels(results.keys(), rotation=45, ha='right')\n",
    "# \n",
    "# for i, (key, value) in enumerate(results.items()):\n",
    "#     ax2.text(i, value + 0.02, f'{value:.3f}', ha='center', fontweight='bold', fontsize=9)\n",
    "# \n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ccfc10",
   "metadata": {},
   "source": [
    "### Performance Metrics Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3ff64c",
   "metadata": {},
   "source": [
    "## 7. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d01e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model and scaler\n",
    "# joblib.dump(best_model, '../Frontend/models/heart_disease_model.sav')\n",
    "# joblib.dump(scaler, '../Frontend/models/heart_disease_scaler.sav')\n",
    "# \n",
    "# print(\"‚úì Model saved to: ../Frontend/models/heart_disease_model.sav\")\n",
    "# print(\"‚úì Scaler saved to: ../Frontend/models/heart_disease_scaler.sav\")\n",
    "# \n",
    "# # Save feature names for reference\n",
    "# feature_names = X.columns.tolist()\n",
    "# import json\n",
    "# with open('../Frontend/models/heart_disease_features.json', 'w') as f:\n",
    "#     json.dump(feature_names, f)\n",
    "# print(\"‚úì Feature names saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affd5ffc",
   "metadata": {},
   "source": [
    "## 8. Usage Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0a5bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Make a prediction\n",
    "# def predict_heart_disease(age, sex, cp, trestbps, chol, fbs, restecg, \n",
    "#                          thalach, exang, oldpeak, slope, ca, thal):\n",
    "#     # Load model and scaler\n",
    "#     model = joblib.load('../Frontend/models/heart_disease_model.sav')\n",
    "#     scaler = joblib.load('../Frontend/models/heart_disease_scaler.sav')\n",
    "#     \n",
    "#     # Create input array\n",
    "#     input_data = np.array([[age, sex, cp, trestbps, chol, fbs, restecg,\n",
    "#                             thalach, exang, oldpeak, slope, ca, thal]])\n",
    "#     \n",
    "#     # Scale and predict\n",
    "#     input_scaled = scaler.transform(input_data)\n",
    "#     prediction = model.predict(input_scaled)[0]\n",
    "#     probability = model.predict_proba(input_scaled)[0]\n",
    "#     \n",
    "#     return prediction, probability\n",
    "# \n",
    "# # Test\n",
    "# pred, proba = predict_heart_disease(\n",
    "#     age=63, sex=1, cp=3, trestbps=145, chol=233, fbs=1, restecg=0,\n",
    "#     thalach=150, exang=0, oldpeak=2.3, slope=0, ca=0, thal=1\n",
    "# )\n",
    "# print(f\"Prediction: {'Heart Disease' if pred == 1 else 'No Disease'}\")\n",
    "# print(f\"Probability: {proba[1]:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8dd495",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Obtain Dataset:** Download heart disease dataset from [Kaggle](https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset) or UCI ML Repository\n",
    "2. **Load Data:** Uncomment and run the data loading cells above\n",
    "3. **Train Model:** Execute all cells sequentially\n",
    "4. **Tune Hyperparameters:** Use GridSearchCV or RandomizedSearchCV for optimization\n",
    "5. **Deploy:** Integrate trained model with Streamlit frontend"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
